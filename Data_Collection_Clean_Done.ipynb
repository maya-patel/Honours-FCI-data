{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from FCI_functions import calculate_post_score, calculate_pre_score, calculate_question_score_post, calculate_question_score_pre, calculate_pre_score_2020, calculate_post_score_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df16_111 = pd.read_excel('rawdata/2016-17 WT1 Phys 111 ALL Data - Shared with Chelsea.xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df16_112 = pd.read_excel('rawdata/2016-17 WT1 Phys 112 ALL Data - Shared with Chelsea.xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df14_111 = pd.read_excel('rawdata/2014-15 WT1 Phys 111 ALL Data - Shared with Chelsea (20210212).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df14_112 = pd.read_excel('rawdata/2014-15 WT1 Phys 112 ALL Data - Shared with Chelsea (20210212).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df15_111 = pd.read_excel('rawdata/2015-16 WT1 Phys 111 ALL Data - Shared with Chelsea.xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df15_112 = pd.read_excel('rawdata/2015-16 WT1 Phys 112 ALL Data - Shared with Chelsea.xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df17_111 = pd.read_excel('rawdata/2017-18 WT1 Phys 111 ALL Data - Shared with David (20190612).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df17_112 = pd.read_excel('rawdata/2017-18 WT1 Phys 112 ALL Data - Shared with David (20190612).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df18_111 = pd.read_excel('rawdata/2018-19 WT1 Phys 111 ALL Data - Shared with David (20190530).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df18_112 = pd.read_excel('rawdata/2018-19 WT1 Phys 112 ALL Data - Shared with David (20190527).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)#.drop(df18_112[df18_112['Secondary'] == L15].index)\n",
    "df20 = pd.read_excel('rawdata/2020-21 WT1 Phys 111&112 ALL Data - Shared with Chelsea (20210329).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "is_111 = df20['Course'] == 111\n",
    "df20_111 = df20[is_111]\n",
    "is_112 = df20['Course'] == 112\n",
    "df20_112 = df20[is_112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_gender_by_year_2020(df, name):\n",
    "    \n",
    "    avg_grade = df[\"Percent Grade\"].mean()\n",
    "    \n",
    "    pre = []\n",
    "    for i in range (1,31):\n",
    "        string = \"PRE Q\" + str(i)\n",
    "        pre.append(string)\n",
    "    post = []\n",
    "    for i in range (1,31):\n",
    "        string = \"POST Q\" + str(i)\n",
    "        post.append(string)\n",
    "\n",
    "    pre_2020 = ['PRE Q1'] \n",
    "    for i in range (24, 53):\n",
    "        string = 'PRE Q' + str(i)\n",
    "        pre_2020.append(string)\n",
    "\n",
    "    post_2020 = ['POST Q1'] \n",
    "    for i in range (35, 64):\n",
    "        string = 'POST Q' + str(i)\n",
    "        post_2020.append(string)\n",
    "\n",
    "    is_f = df['PRE Q12']== 1\n",
    "    df_f = df[is_f]\n",
    "    \n",
    "    avg_grade_f = df_f['Percent Grade'].mean()\n",
    "    \n",
    "    df_pre_f = df_f[pre_2020]\n",
    "    df_post_f = df_f[post_2020]\n",
    "\n",
    "    df_pre_f.columns = pre\n",
    "    df_post_f.columns = post\n",
    "    \n",
    "    df_pre_f = df_pre_f.dropna(thresh=25, axis=0)\n",
    "    df_post_f = df_post_f.dropna(thresh=25, axis=0)\n",
    "    \n",
    "    idx = df_pre_f.index.intersection(df_post_f.index)\n",
    "    \n",
    "    df_pre_f = df_pre_f.loc[idx]\n",
    "    df_post_f = df_post_f.loc[idx]\n",
    "    num_f = len(idx)\n",
    "\n",
    "    pre_f = df_pre_f.apply(calculate_pre_score_2020, axis=1).mean()\n",
    "    pre_f_error = df_pre_f.apply(calculate_pre_score_2020, axis=1).sem(axis=0)\n",
    "    post_f =df_post_f.apply(calculate_post_score_2020, axis=1).mean()\n",
    "    post_f_error = df_post_f.apply(calculate_post_score_2020, axis=1).sem(axis=0)\n",
    "    gain_f = (df_pre_f.apply(calculate_pre_score_2020, axis=1) - df_post_f.apply(calculate_post_score_2020, axis=1)).mean()\n",
    "    norm_f = (post_f-pre_f)/(30-pre_f)\n",
    "    norm_gain_error = (((df_pre_f.apply(calculate_pre_score_2020, axis=1) - df_post_f.apply(calculate_post_score_2020, axis=1)))/(30-(df_pre_f.apply(calculate_pre_score, axis=1)))).sem(axis=0)\n",
    "    gain_f_error = (df_pre_f.apply(calculate_pre_score_2020, axis=1) - df_post_f.apply(calculate_post_score_2020, axis=1)).sem(axis=0)\n",
    "    gain_f_error_1 = np.sqrt(pre_f_error**2 + post_f_error**2)\n",
    "\n",
    "    is_m = df['PRE Q12']== 3\n",
    "    df_m = df[is_m]\n",
    "    \n",
    "    avg_grade_m = df_m['Percent Grade'].mean()\n",
    "    \n",
    "    df_pre_m = df_m[pre_2020]\n",
    "    df_post_m = df_m[post_2020]\n",
    "\n",
    "    df_pre_m.columns = pre\n",
    "    df_post_m.columns = post\n",
    "    \n",
    "    df_pre_m = df_pre_m.dropna(thresh=25, axis=0)\n",
    "    df_post_m = df_post_m.dropna(thresh=25, axis=0)\n",
    "    \n",
    "    idx = df_pre_m.index.intersection(df_post_m.index)\n",
    "    \n",
    "    df_pre_m = df_pre_m.loc[idx]\n",
    "    df_post_m = df_post_m.loc[idx]\n",
    "    num_m = len(idx)\n",
    "\n",
    "    pre_m = df_pre_m.apply(calculate_pre_score_2020, axis=1).mean()\n",
    "    pre_m_error = df_pre_m.apply(calculate_pre_score_2020, axis=1).sem(axis=0)\n",
    "    post_m =df_post_m.apply(calculate_post_score_2020, axis=1).mean()\n",
    "    post_m_error = df_post_m.apply(calculate_post_score_2020, axis=1).sem(axis=0)\n",
    "    gain_m = (df_pre_m.apply(calculate_pre_score_2020, axis=1) - df_post_m.apply(calculate_post_score_2020, axis=1)).mean()\n",
    "    norm_m = (post_m-pre_m)/(30-pre_m)\n",
    "    norm_m_error = (((df_pre_m.apply(calculate_pre_score_2020, axis=1) - df_post_m.apply(calculate_post_score_2020, axis=1)))/(30-(df_pre_m.apply(calculate_pre_score, axis=1)))).sem(axis=0)\n",
    "    gain_m_error = (df_pre_m.apply(calculate_pre_score_2020, axis=1) - df_post_m.apply(calculate_post_score_2020, axis=1)).sem(axis=0)\n",
    "    gain_m_error_1 = np.sqrt(pre_m_error**2 + post_m_error**2)\n",
    "    \n",
    "    num = num_f + num_m\n",
    "\n",
    "    array = [name, avg_grade, pre_f, pre_f_error, post_f, post_f_error, post_f-pre_f, norm_f, norm_gain_error, gain_f_error, gain_f_error_1, num_f, avg_grade_f, pre_m, pre_m_error, post_m, post_m_error, post_m-pre_m, norm_m, norm_m_error, gain_m_error, gain_m_error_1, num_m, avg_grade_m]\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_gender_by_year(df, name):\n",
    "    \n",
    "    avg_grade = df[\"Percent Grade\"].mean()\n",
    "    \n",
    "    pre = []\n",
    "    for i in range (1,31):\n",
    "        string = \"PRE Q\" + str(i)\n",
    "        pre.append(string)\n",
    "    post = []\n",
    "    for i in range (1,31):\n",
    "        string = \"POST Q\" + str(i)\n",
    "        post.append(string)\n",
    "\n",
    "    is_f = df['PRE Q85']== 'A'\n",
    "    df_f = df[is_f]\n",
    "    \n",
    "    df_pre_f = df_f[pre].dropna(thresh=25, axis=0)\n",
    "    df_post_f = df_f[post].dropna(thresh=25, axis=0)\n",
    "    \n",
    "    idx = df_pre_f.index.intersection(df_post_f.index)\n",
    "    \n",
    "    df_pre_f = df_pre_f.loc[idx]\n",
    "    df_post_f = df_post_f.loc[idx]\n",
    "    num_f = len(idx)\n",
    "    \n",
    "    pre_f = df_pre_f.apply(calculate_pre_score, axis=1).mean()\n",
    "    pre_f_error = df_pre_f.apply(calculate_pre_score, axis=1).sem(axis=0)\n",
    "    post_f =df_post_f.apply(calculate_post_score, axis=1).mean()\n",
    "    post_f_error = df_post_f.apply(calculate_post_score, axis=1).sem(axis=0)\n",
    "    norm_f = (post_f-pre_f)/(30-pre_f)\n",
    "    norm_gain_error = (((df_pre_f.apply(calculate_pre_score, axis=1) - df_post_f.apply(calculate_post_score, axis=1)))/(30-(df_pre_f.apply(calculate_pre_score, axis=1)))).sem(axis=0)\n",
    "    gain_f_error = np.sqrt(pre_f_error**2 + post_f_error**2)\n",
    "    gain_f_error_1 = (df_pre_f.apply(calculate_pre_score, axis=1) - df_post_f.apply(calculate_post_score, axis=1)).sem(axis=0)\n",
    "    \n",
    "    avg_grade_f = df_f['Percent Grade'].mean()\n",
    "    \n",
    "    is_m = df['PRE Q85']== 'B'\n",
    "    df_m = df[is_m]\n",
    "    \n",
    "    avg_grade_m = df_m['Percent Grade'].mean()\n",
    "    \n",
    "    df_pre_m = df_m[pre].dropna(thresh=25, axis=0)\n",
    "    df_post_m = df_m[post].dropna(thresh=25, axis=0)\n",
    "    \n",
    "    idx = df_pre_m.index.intersection(df_post_m.index)\n",
    "    \n",
    "    df_pre_m = df_pre_m.loc[idx]\n",
    "    df_post_m = df_post_m.loc[idx]\n",
    "    num_m = len(df_pre_m.index)\n",
    "    \n",
    "    pre_m = df_pre_m.apply(calculate_pre_score, axis=1).mean()\n",
    "    pre_m_error = df_pre_m.apply(calculate_pre_score, axis=1).sem(axis=0)\n",
    "    post_m =df_post_m.apply(calculate_post_score, axis=1).mean()\n",
    "    post_m_error = df_post_m.apply(calculate_post_score, axis=1).sem(axis=0)\n",
    "    norm_m = (post_m-pre_m)/(30-pre_m)\n",
    "    norm_m_error = (((df_pre_m.apply(calculate_pre_score, axis=1) - df_post_m.apply(calculate_post_score, axis=1)))/(30-(df_pre_m.apply(calculate_pre_score, axis=1)))).sem(axis=0)\n",
    "    gain_m_error = np.sqrt(pre_m_error**2 + post_m_error**2)\n",
    "    gain_m_error_1 = (df_pre_m.apply(calculate_pre_score, axis=1) - df_post_m.apply(calculate_post_score, axis=1)).sem(axis=0)\n",
    "    \n",
    "    array = [name, avg_grade, pre_f, pre_f_error, post_f, post_f_error, post_f-pre_f, norm_f, norm_gain_error, gain_f_error, gain_f_error_1, num_f, avg_grade_f, pre_m, pre_m_error, post_m, post_m_error, post_m-pre_m, norm_m, norm_m_error, gain_m_error, gain_m_error_1, num_m, avg_grade_m]\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Avg Grade</th>\n",
       "      <th>Pre Score F</th>\n",
       "      <th>Pre Score F Error</th>\n",
       "      <th>Post Score F</th>\n",
       "      <th>Post Score F Error</th>\n",
       "      <th>Gain F</th>\n",
       "      <th>Norm Gain</th>\n",
       "      <th>Norm Gain Error</th>\n",
       "      <th>Gain Error sqrt</th>\n",
       "      <th>...</th>\n",
       "      <th>Pre Score M Error</th>\n",
       "      <th>Post Score M</th>\n",
       "      <th>Post Score M Error</th>\n",
       "      <th>Gain M</th>\n",
       "      <th>Norm gain M</th>\n",
       "      <th>Norm gain error</th>\n",
       "      <th>Gain M Error</th>\n",
       "      <th>Gain M error sqrt</th>\n",
       "      <th>Num M</th>\n",
       "      <th>Avg M Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014 111</td>\n",
       "      <td>69.474510</td>\n",
       "      <td>12.222222</td>\n",
       "      <td>0.829926</td>\n",
       "      <td>16.266667</td>\n",
       "      <td>0.961585</td>\n",
       "      <td>4.044444</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.028441</td>\n",
       "      <td>1.270206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.722272</td>\n",
       "      <td>20.467742</td>\n",
       "      <td>0.799166</td>\n",
       "      <td>1.483871</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.050007</td>\n",
       "      <td>1.077192</td>\n",
       "      <td>0.438582</td>\n",
       "      <td>62</td>\n",
       "      <td>69.521127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014 112</td>\n",
       "      <td>68.779528</td>\n",
       "      <td>8.310000</td>\n",
       "      <td>0.353252</td>\n",
       "      <td>11.180000</td>\n",
       "      <td>0.468477</td>\n",
       "      <td>2.870000</td>\n",
       "      <td>0.132319</td>\n",
       "      <td>0.017428</td>\n",
       "      <td>0.586735</td>\n",
       "      <td>...</td>\n",
       "      <td>0.591015</td>\n",
       "      <td>14.838710</td>\n",
       "      <td>0.735226</td>\n",
       "      <td>1.661290</td>\n",
       "      <td>0.098754</td>\n",
       "      <td>0.044970</td>\n",
       "      <td>0.943322</td>\n",
       "      <td>0.617026</td>\n",
       "      <td>62</td>\n",
       "      <td>69.171053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015 111</td>\n",
       "      <td>71.400000</td>\n",
       "      <td>12.162500</td>\n",
       "      <td>0.573807</td>\n",
       "      <td>14.187500</td>\n",
       "      <td>0.597488</td>\n",
       "      <td>2.025000</td>\n",
       "      <td>0.113525</td>\n",
       "      <td>0.022854</td>\n",
       "      <td>0.828400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680550</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>0.767277</td>\n",
       "      <td>2.444444</td>\n",
       "      <td>0.190311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.025604</td>\n",
       "      <td>0.418997</td>\n",
       "      <td>90</td>\n",
       "      <td>72.432692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015 112</td>\n",
       "      <td>71.942652</td>\n",
       "      <td>8.467213</td>\n",
       "      <td>0.357092</td>\n",
       "      <td>12.090164</td>\n",
       "      <td>0.447335</td>\n",
       "      <td>3.622951</td>\n",
       "      <td>0.168253</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>0.572384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583750</td>\n",
       "      <td>16.662791</td>\n",
       "      <td>0.688703</td>\n",
       "      <td>3.674419</td>\n",
       "      <td>0.215995</td>\n",
       "      <td>0.030372</td>\n",
       "      <td>0.902816</td>\n",
       "      <td>0.442429</td>\n",
       "      <td>86</td>\n",
       "      <td>75.065934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016 111</td>\n",
       "      <td>73.690909</td>\n",
       "      <td>12.659091</td>\n",
       "      <td>0.553295</td>\n",
       "      <td>15.079545</td>\n",
       "      <td>0.598941</td>\n",
       "      <td>2.420455</td>\n",
       "      <td>0.139581</td>\n",
       "      <td>0.030271</td>\n",
       "      <td>0.815393</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538617</td>\n",
       "      <td>19.353982</td>\n",
       "      <td>0.657655</td>\n",
       "      <td>0.929204</td>\n",
       "      <td>0.080275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850069</td>\n",
       "      <td>0.366009</td>\n",
       "      <td>113</td>\n",
       "      <td>74.929688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016 112</td>\n",
       "      <td>67.096220</td>\n",
       "      <td>8.380368</td>\n",
       "      <td>0.337758</td>\n",
       "      <td>13.141104</td>\n",
       "      <td>0.423311</td>\n",
       "      <td>4.760736</td>\n",
       "      <td>0.220204</td>\n",
       "      <td>0.026061</td>\n",
       "      <td>0.541547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.621685</td>\n",
       "      <td>17.592593</td>\n",
       "      <td>0.761897</td>\n",
       "      <td>3.876543</td>\n",
       "      <td>0.238059</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.983351</td>\n",
       "      <td>0.548112</td>\n",
       "      <td>81</td>\n",
       "      <td>65.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2017 111</td>\n",
       "      <td>72.291391</td>\n",
       "      <td>13.461538</td>\n",
       "      <td>0.844404</td>\n",
       "      <td>15.019231</td>\n",
       "      <td>0.883266</td>\n",
       "      <td>1.557692</td>\n",
       "      <td>0.094186</td>\n",
       "      <td>0.053723</td>\n",
       "      <td>1.221956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.648279</td>\n",
       "      <td>20.036364</td>\n",
       "      <td>0.671215</td>\n",
       "      <td>1.845455</td>\n",
       "      <td>0.156274</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.933165</td>\n",
       "      <td>0.466775</td>\n",
       "      <td>110</td>\n",
       "      <td>75.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2017 112</td>\n",
       "      <td>72.822622</td>\n",
       "      <td>9.341935</td>\n",
       "      <td>0.361355</td>\n",
       "      <td>14.696774</td>\n",
       "      <td>0.455325</td>\n",
       "      <td>5.354839</td>\n",
       "      <td>0.259213</td>\n",
       "      <td>0.018402</td>\n",
       "      <td>0.581290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658544</td>\n",
       "      <td>20.294872</td>\n",
       "      <td>0.609370</td>\n",
       "      <td>5.230769</td>\n",
       "      <td>0.350215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.897224</td>\n",
       "      <td>0.491324</td>\n",
       "      <td>78</td>\n",
       "      <td>75.329545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018 111</td>\n",
       "      <td>77.843750</td>\n",
       "      <td>11.976744</td>\n",
       "      <td>0.811387</td>\n",
       "      <td>12.813953</td>\n",
       "      <td>0.974910</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.046452</td>\n",
       "      <td>0.038899</td>\n",
       "      <td>1.268384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.679742</td>\n",
       "      <td>17.242105</td>\n",
       "      <td>0.687387</td>\n",
       "      <td>-0.126316</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.034499</td>\n",
       "      <td>0.966722</td>\n",
       "      <td>0.317903</td>\n",
       "      <td>95</td>\n",
       "      <td>75.407080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018 112</td>\n",
       "      <td>73.650000</td>\n",
       "      <td>9.790419</td>\n",
       "      <td>0.365908</td>\n",
       "      <td>14.107784</td>\n",
       "      <td>0.438484</td>\n",
       "      <td>4.317365</td>\n",
       "      <td>0.213630</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>0.571102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575450</td>\n",
       "      <td>18.701149</td>\n",
       "      <td>0.658081</td>\n",
       "      <td>4.241379</td>\n",
       "      <td>0.272929</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.874193</td>\n",
       "      <td>0.467313</td>\n",
       "      <td>87</td>\n",
       "      <td>73.434343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020 111</td>\n",
       "      <td>80.904382</td>\n",
       "      <td>12.333333</td>\n",
       "      <td>0.707254</td>\n",
       "      <td>14.894737</td>\n",
       "      <td>0.801269</td>\n",
       "      <td>2.561404</td>\n",
       "      <td>0.144985</td>\n",
       "      <td>0.023048</td>\n",
       "      <td>0.691434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520026</td>\n",
       "      <td>17.963964</td>\n",
       "      <td>0.698533</td>\n",
       "      <td>3.198198</td>\n",
       "      <td>0.209935</td>\n",
       "      <td>0.019097</td>\n",
       "      <td>0.572910</td>\n",
       "      <td>0.870848</td>\n",
       "      <td>111</td>\n",
       "      <td>79.961290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020 112</td>\n",
       "      <td>75.842932</td>\n",
       "      <td>9.376744</td>\n",
       "      <td>0.273692</td>\n",
       "      <td>13.646512</td>\n",
       "      <td>0.386389</td>\n",
       "      <td>4.269767</td>\n",
       "      <td>0.207037</td>\n",
       "      <td>0.010374</td>\n",
       "      <td>0.311217</td>\n",
       "      <td>...</td>\n",
       "      <td>0.541355</td>\n",
       "      <td>15.753086</td>\n",
       "      <td>0.820180</td>\n",
       "      <td>3.506173</td>\n",
       "      <td>0.197497</td>\n",
       "      <td>0.024749</td>\n",
       "      <td>0.742477</td>\n",
       "      <td>0.982731</td>\n",
       "      <td>81</td>\n",
       "      <td>76.551724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR  Avg Grade  Pre Score F  Pre Score F Error  Post Score F  \\\n",
       "1   2014 111  69.474510    12.222222           0.829926     16.266667   \n",
       "2   2014 112  68.779528     8.310000           0.353252     11.180000   \n",
       "3   2015 111  71.400000    12.162500           0.573807     14.187500   \n",
       "4   2015 112  71.942652     8.467213           0.357092     12.090164   \n",
       "5   2016 111  73.690909    12.659091           0.553295     15.079545   \n",
       "6   2016 112  67.096220     8.380368           0.337758     13.141104   \n",
       "7   2017 111  72.291391    13.461538           0.844404     15.019231   \n",
       "8   2017 112  72.822622     9.341935           0.361355     14.696774   \n",
       "9   2018 111  77.843750    11.976744           0.811387     12.813953   \n",
       "10  2018 112  73.650000     9.790419           0.365908     14.107784   \n",
       "11  2020 111  80.904382    12.333333           0.707254     14.894737   \n",
       "12  2020 112  75.842932     9.376744           0.273692     13.646512   \n",
       "\n",
       "    Post Score F Error    Gain F  Norm Gain  Norm Gain Error  Gain Error sqrt  \\\n",
       "1             0.961585  4.044444   0.227500         0.028441         1.270206   \n",
       "2             0.468477  2.870000   0.132319         0.017428         0.586735   \n",
       "3             0.597488  2.025000   0.113525         0.022854         0.828400   \n",
       "4             0.447335  3.622951   0.168253         0.016573         0.572384   \n",
       "5             0.598941  2.420455   0.139581         0.030271         0.815393   \n",
       "6             0.423311  4.760736   0.220204         0.026061         0.541547   \n",
       "7             0.883266  1.557692   0.094186         0.053723         1.221956   \n",
       "8             0.455325  5.354839   0.259213         0.018402         0.581290   \n",
       "9             0.974910  0.837209   0.046452         0.038899         1.268384   \n",
       "10            0.438484  4.317365   0.213630         0.016885         0.571102   \n",
       "11            0.801269  2.561404   0.144985         0.023048         0.691434   \n",
       "12            0.386389  4.269767   0.207037         0.010374         0.311217   \n",
       "\n",
       "    ...  Pre Score M Error Post Score M  Post Score M Error    Gain M  \\\n",
       "1   ...           0.722272    20.467742            0.799166  1.483871   \n",
       "2   ...           0.591015    14.838710            0.735226  1.661290   \n",
       "3   ...           0.680550    19.600000            0.767277  2.444444   \n",
       "4   ...           0.583750    16.662791            0.688703  3.674419   \n",
       "5   ...           0.538617    19.353982            0.657655  0.929204   \n",
       "6   ...           0.621685    17.592593            0.761897  3.876543   \n",
       "7   ...           0.648279    20.036364            0.671215  1.845455   \n",
       "8   ...           0.658544    20.294872            0.609370  5.230769   \n",
       "9   ...           0.679742    17.242105            0.687387 -0.126316   \n",
       "10  ...           0.575450    18.701149            0.658081  4.241379   \n",
       "11  ...           0.520026    17.963964            0.698533  3.198198   \n",
       "12  ...           0.541355    15.753086            0.820180  3.506173   \n",
       "\n",
       "    Norm gain M  Norm gain error  Gain M Error  Gain M error sqrt  Num M  \\\n",
       "1      0.134700         0.050007      1.077192           0.438582     62   \n",
       "2      0.098754         0.044970      0.943322           0.617026     62   \n",
       "3      0.190311              NaN      1.025604           0.418997     90   \n",
       "4      0.215995         0.030372      0.902816           0.442429     86   \n",
       "5      0.080275              NaN      0.850069           0.366009    113   \n",
       "6      0.238059         0.043003      0.983351           0.548112     81   \n",
       "7      0.156274              NaN      0.933165           0.466775    110   \n",
       "8      0.350215              NaN      0.897224           0.491324     78   \n",
       "9     -0.010000         0.034499      0.966722           0.317903     95   \n",
       "10     0.272929         0.033626      0.874193           0.467313     87   \n",
       "11     0.209935         0.019097      0.572910           0.870848    111   \n",
       "12     0.197497         0.024749      0.742477           0.982731     81   \n",
       "\n",
       "    Avg M Grade  \n",
       "1     69.521127  \n",
       "2     69.171053  \n",
       "3     72.432692  \n",
       "4     75.065934  \n",
       "5     74.929688  \n",
       "6     65.086957  \n",
       "7     75.616667  \n",
       "8     75.329545  \n",
       "9     75.407080  \n",
       "10    73.434343  \n",
       "11    79.961290  \n",
       "12    76.551724  \n",
       "\n",
       "[12 rows x 24 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create table of average scores by gender by year\n",
    "column_names=[\"YEAR\", \"Avg Grade\", \"Pre Score F\", \"Pre Score F Error\", \"Post Score F\",\"Post Score F Error\", \"Gain F\", \"Norm Gain\", \"Norm Gain Error\", \"Gain Error sqrt\",\"Gain Error\", \"Num F\", \"Avg Grade F\", \"Pre Score M\", \"Pre Score M Error\", \"Post Score M\", \"Post Score M Error\", \"Gain M\", \"Norm gain M\", \"Norm gain error\", \"Gain M Error\", \"Gain M error sqrt\", \"Num M\", \"Avg M Grade\"]\n",
    "df4 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "df4.loc[1] = by_gender_by_year(df14_111, \"2014 111\")\n",
    "df4.loc[2] = by_gender_by_year(df14_112, \"2014 112\")\n",
    "df4.loc[3] = by_gender_by_year(df15_111, \"2015 111\")\n",
    "df4.loc[4] = by_gender_by_year(df15_112, \"2015 112\")\n",
    "df4.loc[5] = by_gender_by_year(df16_111, \"2016 111\")\n",
    "df4.loc[6] = by_gender_by_year(df16_112, \"2016 112\")\n",
    "df4.loc[7] = by_gender_by_year(df17_111, \"2017 111\")\n",
    "df4.loc[8] = by_gender_by_year(df17_112, \"2017 112\")\n",
    "df4.loc[9] = by_gender_by_year(df18_111, \"2018 111\")\n",
    "df4.loc[10] = by_gender_by_year(df18_112, \"2018 112\")\n",
    "df4.loc[11] = by_gender_by_year_2020(df20_111, \"2020 111\")\n",
    "df4.loc[12] = by_gender_by_year_2020(df20_112, \"2020 112\")\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.to_excel(\"2014-2020_by_gender_by_year.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEAR                   2020 112\n",
       "Pre Score F            9.376744\n",
       "Pre Score F Error      0.273692\n",
       "Post Score F          13.646512\n",
       "Post Score F Error     0.386389\n",
       "Gain F                 4.269767\n",
       "Norm Gain              0.207037\n",
       "Norm Gain Error        0.010374\n",
       "Gain Error sqrt        0.311217\n",
       "Gain Error             0.473502\n",
       "Num F                       215\n",
       "Pre Score M           12.246914\n",
       "Pre Score M Error      0.541355\n",
       "Post Score M          15.753086\n",
       "Post Score M Error      0.82018\n",
       "Gain M                 3.506173\n",
       "Norm gain M            0.197497\n",
       "Norm gain error        0.024749\n",
       "Gain M Error           0.742477\n",
       "Gain M error sqrt      0.982731\n",
       "Num M                        81\n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.iloc[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
