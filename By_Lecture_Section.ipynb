{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from FCI_functions import calculate_post_score, calculate_pre_score, calculate_question_score_post, calculate_question_score_pre, calculate_pre_score_2020, calculate_post_score_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df16_111 = pd.read_excel('rawdata/2016-17 WT1 Phys 111 ALL Data - Shared with Chelsea.xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df16_112 = pd.read_excel('rawdata/2016-17 WT1 Phys 112 ALL Data - Shared with Chelsea.xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df14_111 = pd.read_excel('rawdata/2014-15 WT1 Phys 111 ALL Data - Shared with Chelsea (20210212).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df14_112 = pd.read_excel('rawdata/2014-15 WT1 Phys 112 ALL Data - Shared with Chelsea (20210212).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df15_111 = pd.read_excel('rawdata/2015-16 WT1 Phys 111 ALL Data - Shared with Chelsea.xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df15_112 = pd.read_excel('rawdata/2015-16 WT1 Phys 112 ALL Data - Shared with Chelsea.xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df17_111 = pd.read_excel('rawdata/2017-18 WT1 Phys 111 ALL Data - Shared with David (20190612).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df17_112 = pd.read_excel('rawdata/2017-18 WT1 Phys 112 ALL Data - Shared with David (20190612).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df18_111 = pd.read_excel('rawdata/2018-19 WT1 Phys 111 ALL Data - Shared with David (20190530).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df18_112 = pd.read_excel('rawdata/2018-19 WT1 Phys 112 ALL Data - Shared with David (20190527).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)#.drop(df18_112[df18_112['Secondary'] == L15].index)\n",
    "df19_111 = pd.read_excel('rawdata/2019-20 WT1 Phys 111 ALL Data - Shared with Maya (20211222).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "df19_112 = pd.read_excel('rawdata/2019-20 WT1 Phys 112 ALL Data - Shared with Maya (20211222).xlsx').replace([\"BLANK\", \"!!\", \"MULT\"], np.nan)\n",
    "\n",
    "df20 = pd.read_excel('rawdata/2020-21 WT1 Phys 111&112 ALL Data - Shared with Chelsea (20210329).xlsx').replace([\"BLANK\", \"!!\", \"MULT\", 0], np.nan)\n",
    "is_111 = df20['Course'] == 111\n",
    "df20_111 = df20[is_111]\n",
    "is_112 = df20['Course'] == 112\n",
    "df20_112 = df20[is_112]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_112_001 = df19_112['Lecture'] == 1\n",
    "df19_112_001 = df19_112[is_112_001]\n",
    "is_112_002 = df19_112['Lecture'] == 2\n",
    "df19_112_002 = df19_112[is_112_002]\n",
    "\n",
    "is_112_001_20 = df20_112['Lecture'] == 1\n",
    "df20_112_001 = df20_112[is_112_001_20]\n",
    "is_112_002_20 = df20_112['Lecture'] == 2\n",
    "df20_112_002 = df20_112[is_112_002_20]\n",
    "\n",
    "is_112_001_18 = df18_112['Lecture'] == 1\n",
    "df18_112_001 = df18_112[is_112_001_18]\n",
    "is_112_002_18 = df18_112['Lecture'] == 2\n",
    "df18_112_002 = df18_112[is_112_002_18]\n",
    "\n",
    "is_112_001_16 = df16_112['Lecture'] == 1\n",
    "df16_112_001 = df16_112[is_112_001_16]\n",
    "is_112_002_16 = df16_112['Lecture'] == 2\n",
    "df16_112_002 = df16_112[is_112_002_16]\n",
    "is_112_003_16 = df16_112['Lecture'] == 3\n",
    "df16_112_003 = df16_112[is_112_003_16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_gender_by_year_2020(df, name):\n",
    "    \n",
    "    avg_grade = df[\"Percent Grade\"].mean()\n",
    "    avg_grade_error = df['Percent Grade'].sem()\n",
    "    \n",
    "    pre = []\n",
    "    for i in range (1,31):\n",
    "        string = \"PRE Q\" + str(i)\n",
    "        pre.append(string)\n",
    "    post = []\n",
    "    for i in range (1,31):\n",
    "        string = \"POST Q\" + str(i)\n",
    "        post.append(string)\n",
    "\n",
    "    pre_2020 = ['PRE Q1'] \n",
    "    for i in range (24, 53):\n",
    "        string = 'PRE Q' + str(i)\n",
    "        pre_2020.append(string)\n",
    "\n",
    "    post_2020 = ['POST Q1'] \n",
    "    for i in range (35, 64):\n",
    "        string = 'POST Q' + str(i)\n",
    "        post_2020.append(string)\n",
    "\n",
    "    is_f = df['PRE Q12']== 1\n",
    "    df_f = df[is_f]\n",
    "    \n",
    "    avg_grade_f = df_f['Percent Grade'].mean()\n",
    "    avg_grade_f_error = df_f['Percent Grade'].sem()\n",
    "    \n",
    "    df_pre_f = df_f[pre_2020]\n",
    "    df_post_f = df_f[post_2020]\n",
    "\n",
    "    df_pre_f.columns = pre\n",
    "    df_post_f.columns = post\n",
    "    \n",
    "    df_pre_f = df_pre_f.dropna(thresh=25, axis=0)\n",
    "    df_post_f = df_post_f.dropna(thresh=25, axis=0)\n",
    "    \n",
    "    idx = df_pre_f.index.intersection(df_post_f.index)\n",
    "    \n",
    "    df_pre_f = df_pre_f.loc[idx]\n",
    "    df_post_f = df_post_f.loc[idx]\n",
    "    num_f = len(idx)\n",
    "\n",
    "    pre_f = df_pre_f.apply(calculate_pre_score_2020, axis=1).mean()\n",
    "    pre_f_error = df_pre_f.apply(calculate_pre_score_2020, axis=1).sem(axis=0)\n",
    "    post_f =df_post_f.apply(calculate_post_score_2020, axis=1).mean()\n",
    "    post_f_error = df_post_f.apply(calculate_post_score_2020, axis=1).sem(axis=0)\n",
    "    gain_f = (df_pre_f.apply(calculate_pre_score_2020, axis=1) - df_post_f.apply(calculate_post_score_2020, axis=1)).mean()\n",
    "    norm_f = (post_f-pre_f)/(30-pre_f)\n",
    "    norm_gain_error = (((df_pre_f.apply(calculate_pre_score_2020, axis=1) - df_post_f.apply(calculate_post_score_2020, axis=1)))/(30-(df_pre_f.apply(calculate_pre_score, axis=1)))).sem(axis=0)\n",
    "    gain_f_error = (df_pre_f.apply(calculate_pre_score_2020, axis=1) - df_post_f.apply(calculate_post_score_2020, axis=1)).sem(axis=0)\n",
    "    gain_f_error_1 = np.sqrt(pre_f_error**2 + post_f_error**2)\n",
    "\n",
    "    is_m = df['PRE Q12']== 3\n",
    "    df_m = df[is_m]\n",
    "    \n",
    "    avg_grade_m = df_m['Percent Grade'].mean()\n",
    "    avg_grade_m_error = df_m['Percent Grade'].sem()\n",
    "    \n",
    "    df_pre_m = df_m[pre_2020]\n",
    "    df_post_m = df_m[post_2020]\n",
    "\n",
    "    df_pre_m.columns = pre\n",
    "    df_post_m.columns = post\n",
    "    \n",
    "    df_pre_m = df_pre_m.dropna(thresh=25, axis=0)\n",
    "    df_post_m = df_post_m.dropna(thresh=25, axis=0)\n",
    "    \n",
    "    idx = df_pre_m.index.intersection(df_post_m.index)\n",
    "    \n",
    "    df_pre_m = df_pre_m.loc[idx]\n",
    "    df_post_m = df_post_m.loc[idx]\n",
    "    num_m = len(idx)\n",
    "\n",
    "    pre_m = df_pre_m.apply(calculate_pre_score_2020, axis=1).mean()\n",
    "    pre_m_error = df_pre_m.apply(calculate_pre_score_2020, axis=1).sem(axis=0)\n",
    "    post_m =df_post_m.apply(calculate_post_score_2020, axis=1).mean()\n",
    "    post_m_error = df_post_m.apply(calculate_post_score_2020, axis=1).sem(axis=0)\n",
    "    gain_m = (df_pre_m.apply(calculate_pre_score_2020, axis=1) - df_post_m.apply(calculate_post_score_2020, axis=1)).mean()\n",
    "    norm_m = (post_m-pre_m)/(30-pre_m)\n",
    "    norm_m_error = (((df_pre_m.apply(calculate_pre_score_2020, axis=1) - df_post_m.apply(calculate_post_score_2020, axis=1)))/(30-(df_pre_m.apply(calculate_pre_score, axis=1)))).sem(axis=0)\n",
    "    gain_m_error = (df_pre_m.apply(calculate_pre_score_2020, axis=1) - df_post_m.apply(calculate_post_score_2020, axis=1)).sem(axis=0)\n",
    "    gain_m_error_1 = np.sqrt(pre_m_error**2 + post_m_error**2)\n",
    "    \n",
    "    num = num_f + num_m\n",
    "\n",
    "    array = [name, avg_grade, avg_grade_error, pre_f, pre_f_error, post_f, post_f_error, post_f-pre_f, norm_f, norm_gain_error, gain_f_error, gain_f_error_1, num_f, avg_grade_f, avg_grade_f_error, pre_m, pre_m_error, post_m, post_m_error, post_m-pre_m, norm_m, norm_m_error, gain_m_error, gain_m_error_1, num_m, avg_grade_m, avg_grade_m_error]\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def by_gender_by_year(df, name):\n",
    "    \n",
    "    avg_grade = df[\"Percent Grade\"].mean()\n",
    "    avg_grade_error = df['Percent Grade'].sem()\n",
    "    \n",
    "    pre = []\n",
    "    for i in range (1,31):\n",
    "        string = \"PRE Q\" + str(i)\n",
    "        pre.append(string)\n",
    "    post = []\n",
    "    for i in range (1,31):\n",
    "        string = \"POST Q\" + str(i)\n",
    "        post.append(string)\n",
    "\n",
    "    is_f = df['PRE Q85']== 'A'\n",
    "    df_f = df[is_f]\n",
    "    \n",
    "    df_pre_f = df_f[pre].dropna(thresh=25, axis=0)\n",
    "    df_post_f = df_f[post].dropna(thresh=25, axis=0)\n",
    "    \n",
    "    idx = df_pre_f.index.intersection(df_post_f.index)\n",
    "    \n",
    "    df_pre_f = df_pre_f.loc[idx]\n",
    "    df_post_f = df_post_f.loc[idx]\n",
    "    num_f = len(idx)\n",
    "    \n",
    "    pre_f = df_pre_f.apply(calculate_pre_score, axis=1).mean()\n",
    "    pre_f_error = df_pre_f.apply(calculate_pre_score, axis=1).sem(axis=0)\n",
    "    post_f =df_post_f.apply(calculate_post_score, axis=1).mean()\n",
    "    post_f_error = df_post_f.apply(calculate_post_score, axis=1).sem(axis=0)\n",
    "    norm_f = (post_f-pre_f)/(30-pre_f)\n",
    "    norm_gain_error = (((df_pre_f.apply(calculate_pre_score, axis=1) - df_post_f.apply(calculate_post_score, axis=1)))/(30-(df_pre_f.apply(calculate_pre_score, axis=1)))).sem(axis=0)\n",
    "    gain_f_error = np.sqrt(pre_f_error**2 + post_f_error**2)\n",
    "    gain_f_error_1 = (df_pre_f.apply(calculate_pre_score, axis=1) - df_post_f.apply(calculate_post_score, axis=1)).sem(axis=0)\n",
    "    \n",
    "    avg_grade_f = df_f['Percent Grade'].mean()\n",
    "    avg_grade_f_error = df_f['Percent Grade'].sem()\n",
    "    \n",
    "    is_m = df['PRE Q85']== 'B'\n",
    "    df_m = df[is_m]\n",
    "    \n",
    "    avg_grade_m = df_m['Percent Grade'].mean()\n",
    "    avg_grade_m_error = df_m['Percent Grade'].sem()\n",
    "    \n",
    "    df_pre_m = df_m[pre].dropna(thresh=25, axis=0)\n",
    "    df_post_m = df_m[post].dropna(thresh=25, axis=0)\n",
    "    \n",
    "    idx = df_pre_m.index.intersection(df_post_m.index)\n",
    "    \n",
    "    df_pre_m = df_pre_m.loc[idx]\n",
    "    df_post_m = df_post_m.loc[idx]\n",
    "    num_m = len(df_pre_m.index)\n",
    "    \n",
    "    pre_m = df_pre_m.apply(calculate_pre_score, axis=1).mean()\n",
    "    pre_m_error = df_pre_m.apply(calculate_pre_score, axis=1).sem(axis=0)\n",
    "    post_m =df_post_m.apply(calculate_post_score, axis=1).mean()\n",
    "    post_m_error = df_post_m.apply(calculate_post_score, axis=1).sem(axis=0)\n",
    "    norm_m = (post_m-pre_m)/(30-pre_m)\n",
    "    norm_m_error = (((df_pre_m.apply(calculate_pre_score, axis=1) - df_post_m.apply(calculate_post_score, axis=1)))/(30-(df_pre_m.apply(calculate_pre_score, axis=1)))).sem(axis=0)\n",
    "    gain_m_error = np.sqrt(pre_m_error**2 + post_m_error**2)\n",
    "    gain_m_error_1 = (df_pre_m.apply(calculate_pre_score, axis=1) - df_post_m.apply(calculate_post_score, axis=1)).sem(axis=0)\n",
    "    \n",
    "    array = [name, avg_grade, avg_grade_error, pre_f, pre_f_error, post_f, post_f_error, post_f-pre_f, norm_f, norm_gain_error, gain_f_error, gain_f_error_1, num_f, avg_grade_f, avg_grade_f_error, pre_m, pre_m_error, post_m, post_m_error, post_m-pre_m, norm_m, norm_m_error, gain_m_error, gain_m_error_1, num_m, avg_grade_m, avg_grade_m_error]\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Avg Grade</th>\n",
       "      <th>Avg Grade Error</th>\n",
       "      <th>Pre Score F</th>\n",
       "      <th>Pre Score F Error</th>\n",
       "      <th>Post Score F</th>\n",
       "      <th>Post Score F Error</th>\n",
       "      <th>Gain F</th>\n",
       "      <th>Norm Gain</th>\n",
       "      <th>Norm Gain Error</th>\n",
       "      <th>...</th>\n",
       "      <th>Post Score M</th>\n",
       "      <th>Post Score M Error</th>\n",
       "      <th>Gain M</th>\n",
       "      <th>Norm gain M</th>\n",
       "      <th>Norm gain error</th>\n",
       "      <th>Gain M Error</th>\n",
       "      <th>Gain M error sqrt</th>\n",
       "      <th>Num M</th>\n",
       "      <th>Avg M Grade</th>\n",
       "      <th>Avg M grade error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019 111</td>\n",
       "      <td>71.595455</td>\n",
       "      <td>1.032202</td>\n",
       "      <td>12.234043</td>\n",
       "      <td>0.899796</td>\n",
       "      <td>15.255319</td>\n",
       "      <td>0.965869</td>\n",
       "      <td>3.021277</td>\n",
       "      <td>0.170060</td>\n",
       "      <td>0.041188</td>\n",
       "      <td>...</td>\n",
       "      <td>20.819549</td>\n",
       "      <td>0.560005</td>\n",
       "      <td>2.609023</td>\n",
       "      <td>0.221301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.801634</td>\n",
       "      <td>0.329120</td>\n",
       "      <td>133</td>\n",
       "      <td>73.276596</td>\n",
       "      <td>1.245218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019 112</td>\n",
       "      <td>77.573913</td>\n",
       "      <td>0.678243</td>\n",
       "      <td>10.148352</td>\n",
       "      <td>0.332639</td>\n",
       "      <td>15.032967</td>\n",
       "      <td>0.388101</td>\n",
       "      <td>4.884615</td>\n",
       "      <td>0.246056</td>\n",
       "      <td>0.016838</td>\n",
       "      <td>...</td>\n",
       "      <td>18.845361</td>\n",
       "      <td>0.657259</td>\n",
       "      <td>4.505155</td>\n",
       "      <td>0.287689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.912898</td>\n",
       "      <td>0.417642</td>\n",
       "      <td>97</td>\n",
       "      <td>77.485149</td>\n",
       "      <td>1.439720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019 112 001</td>\n",
       "      <td>76.920000</td>\n",
       "      <td>0.824998</td>\n",
       "      <td>9.891892</td>\n",
       "      <td>0.438401</td>\n",
       "      <td>15.126126</td>\n",
       "      <td>0.510835</td>\n",
       "      <td>5.234234</td>\n",
       "      <td>0.260305</td>\n",
       "      <td>0.020316</td>\n",
       "      <td>...</td>\n",
       "      <td>19.529412</td>\n",
       "      <td>0.955624</td>\n",
       "      <td>4.470588</td>\n",
       "      <td>0.299213</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>1.343908</td>\n",
       "      <td>0.622678</td>\n",
       "      <td>51</td>\n",
       "      <td>79.735849</td>\n",
       "      <td>1.698875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019 112 002</td>\n",
       "      <td>78.475862</td>\n",
       "      <td>1.143492</td>\n",
       "      <td>10.549296</td>\n",
       "      <td>0.507405</td>\n",
       "      <td>14.887324</td>\n",
       "      <td>0.597294</td>\n",
       "      <td>4.338028</td>\n",
       "      <td>0.223027</td>\n",
       "      <td>0.028948</td>\n",
       "      <td>...</td>\n",
       "      <td>18.086957</td>\n",
       "      <td>0.891086</td>\n",
       "      <td>4.543478</td>\n",
       "      <td>0.276090</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.213663</td>\n",
       "      <td>0.554042</td>\n",
       "      <td>46</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>2.345964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           YEAR  Avg Grade  Avg Grade Error  Pre Score F  Pre Score F Error  \\\n",
       "1      2019 111  71.595455         1.032202    12.234043           0.899796   \n",
       "4      2019 112  77.573913         0.678243    10.148352           0.332639   \n",
       "5  2019 112 001  76.920000         0.824998     9.891892           0.438401   \n",
       "6  2019 112 002  78.475862         1.143492    10.549296           0.507405   \n",
       "\n",
       "   Post Score F  Post Score F Error    Gain F  Norm Gain  Norm Gain Error  \\\n",
       "1     15.255319            0.965869  3.021277   0.170060         0.041188   \n",
       "4     15.032967            0.388101  4.884615   0.246056         0.016838   \n",
       "5     15.126126            0.510835  5.234234   0.260305         0.020316   \n",
       "6     14.887324            0.597294  4.338028   0.223027         0.028948   \n",
       "\n",
       "   ...  Post Score M  Post Score M Error    Gain M  Norm gain M  \\\n",
       "1  ...     20.819549            0.560005  2.609023     0.221301   \n",
       "4  ...     18.845361            0.657259  4.505155     0.287689   \n",
       "5  ...     19.529412            0.955624  4.470588     0.299213   \n",
       "6  ...     18.086957            0.891086  4.543478     0.276090   \n",
       "\n",
       "   Norm gain error  Gain M Error  Gain M error sqrt  Num M  Avg M Grade  \\\n",
       "1              NaN      0.801634           0.329120    133    73.276596   \n",
       "4              NaN      0.912898           0.417642     97    77.485149   \n",
       "5         0.046829      1.343908           0.622678     51    79.735849   \n",
       "6              NaN      1.213663           0.554042     46    75.000000   \n",
       "\n",
       "   Avg M grade error  \n",
       "1           1.245218  \n",
       "4           1.439720  \n",
       "5           1.698875  \n",
       "6           2.345964  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2019\n",
    "\n",
    "df5 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "df5.loc[1] = by_gender_by_year(df19_111, \"2019 111\")\n",
    "df5.loc[4] = by_gender_by_year(df19_112, \"2019 112\")\n",
    "df5.loc[5] = by_gender_by_year(df19_112_001, \"2019 112 001\")\n",
    "df5.loc[6] = by_gender_by_year(df19_112_002, \"2019 112 002\")\n",
    "\n",
    "df5.to_excel(\"2019_by_lecture_section.xlsx\")\n",
    "\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Avg Grade</th>\n",
       "      <th>Avg Grade Error</th>\n",
       "      <th>Pre Score F</th>\n",
       "      <th>Pre Score F Error</th>\n",
       "      <th>Post Score F</th>\n",
       "      <th>Post Score F Error</th>\n",
       "      <th>Gain F</th>\n",
       "      <th>Norm Gain</th>\n",
       "      <th>Norm Gain Error</th>\n",
       "      <th>...</th>\n",
       "      <th>Post Score M</th>\n",
       "      <th>Post Score M Error</th>\n",
       "      <th>Gain M</th>\n",
       "      <th>Norm gain M</th>\n",
       "      <th>Norm gain error</th>\n",
       "      <th>Gain M Error</th>\n",
       "      <th>Gain M error sqrt</th>\n",
       "      <th>Num M</th>\n",
       "      <th>Avg M Grade</th>\n",
       "      <th>Avg M grade error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020 111</td>\n",
       "      <td>80.904382</td>\n",
       "      <td>0.816422</td>\n",
       "      <td>12.460000</td>\n",
       "      <td>0.728549</td>\n",
       "      <td>15.760000</td>\n",
       "      <td>0.784316</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>0.188141</td>\n",
       "      <td>0.017747</td>\n",
       "      <td>...</td>\n",
       "      <td>19.254902</td>\n",
       "      <td>0.591909</td>\n",
       "      <td>4.245098</td>\n",
       "      <td>0.283192</td>\n",
       "      <td>0.014981</td>\n",
       "      <td>0.449430</td>\n",
       "      <td>0.806350</td>\n",
       "      <td>102</td>\n",
       "      <td>79.961290</td>\n",
       "      <td>1.112404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020 112</td>\n",
       "      <td>75.842932</td>\n",
       "      <td>0.685715</td>\n",
       "      <td>9.765625</td>\n",
       "      <td>0.286896</td>\n",
       "      <td>14.088542</td>\n",
       "      <td>0.391246</td>\n",
       "      <td>4.322917</td>\n",
       "      <td>0.213642</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>...</td>\n",
       "      <td>16.760563</td>\n",
       "      <td>0.810511</td>\n",
       "      <td>4.281690</td>\n",
       "      <td>0.244373</td>\n",
       "      <td>0.020536</td>\n",
       "      <td>0.616077</td>\n",
       "      <td>0.987920</td>\n",
       "      <td>71</td>\n",
       "      <td>76.551724</td>\n",
       "      <td>1.231724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020 112 001</td>\n",
       "      <td>77.690583</td>\n",
       "      <td>0.840796</td>\n",
       "      <td>10.307087</td>\n",
       "      <td>0.390090</td>\n",
       "      <td>15.362205</td>\n",
       "      <td>0.487780</td>\n",
       "      <td>5.055118</td>\n",
       "      <td>0.256697</td>\n",
       "      <td>0.012868</td>\n",
       "      <td>...</td>\n",
       "      <td>18.297872</td>\n",
       "      <td>0.935434</td>\n",
       "      <td>5.510638</td>\n",
       "      <td>0.320148</td>\n",
       "      <td>0.022712</td>\n",
       "      <td>0.681371</td>\n",
       "      <td>1.187294</td>\n",
       "      <td>47</td>\n",
       "      <td>78.859375</td>\n",
       "      <td>1.470589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020 112 002</td>\n",
       "      <td>73.251572</td>\n",
       "      <td>1.121685</td>\n",
       "      <td>8.707692</td>\n",
       "      <td>0.337356</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>0.536549</td>\n",
       "      <td>2.892308</td>\n",
       "      <td>0.135838</td>\n",
       "      <td>0.014747</td>\n",
       "      <td>...</td>\n",
       "      <td>13.750000</td>\n",
       "      <td>1.375576</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.036796</td>\n",
       "      <td>1.103868</td>\n",
       "      <td>1.626950</td>\n",
       "      <td>24</td>\n",
       "      <td>73.711538</td>\n",
       "      <td>2.014154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           YEAR  Avg Grade  Avg Grade Error  Pre Score F  Pre Score F Error  \\\n",
       "1      2020 111  80.904382         0.816422    12.460000           0.728549   \n",
       "4      2020 112  75.842932         0.685715     9.765625           0.286896   \n",
       "5  2020 112 001  77.690583         0.840796    10.307087           0.390090   \n",
       "6  2020 112 002  73.251572         1.121685     8.707692           0.337356   \n",
       "\n",
       "   Post Score F  Post Score F Error    Gain F  Norm Gain  Norm Gain Error  \\\n",
       "1     15.760000            0.784316  3.300000   0.188141         0.017747   \n",
       "4     14.088542            0.391246  4.322917   0.213642         0.010150   \n",
       "5     15.362205            0.487780  5.055118   0.256697         0.012868   \n",
       "6     11.600000            0.536549  2.892308   0.135838         0.014747   \n",
       "\n",
       "   ...  Post Score M  Post Score M Error    Gain M  Norm gain M  \\\n",
       "1  ...     19.254902            0.591909  4.245098     0.283192   \n",
       "4  ...     16.760563            0.810511  4.281690     0.244373   \n",
       "5  ...     18.297872            0.935434  5.510638     0.320148   \n",
       "6  ...     13.750000            1.375576  1.875000     0.103448   \n",
       "\n",
       "   Norm gain error  Gain M Error  Gain M error sqrt  Num M  Avg M Grade  \\\n",
       "1         0.014981      0.449430           0.806350    102    79.961290   \n",
       "4         0.020536      0.616077           0.987920     71    76.551724   \n",
       "5         0.022712      0.681371           1.187294     47    78.859375   \n",
       "6         0.036796      1.103868           1.626950     24    73.711538   \n",
       "\n",
       "   Avg M grade error  \n",
       "1           1.112404  \n",
       "4           1.231724  \n",
       "5           1.470589  \n",
       "6           2.014154  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2020\n",
    "\n",
    "df6 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "df6.loc[1] = by_gender_by_year_2020(df20_111, \"2020 111\")\n",
    "df6.loc[4] = by_gender_by_year_2020(df20_112, \"2020 112\")\n",
    "df6.loc[5] = by_gender_by_year_2020(df20_112_001, \"2020 112 001\")\n",
    "df6.loc[6] = by_gender_by_year_2020(df20_112_002, \"2020 112 002\")\n",
    "\n",
    "df6.to_excel(\"2020_by_lecture_section.xlsx\")\n",
    "\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Avg Grade</th>\n",
       "      <th>Avg Grade Error</th>\n",
       "      <th>Pre Score F</th>\n",
       "      <th>Pre Score F Error</th>\n",
       "      <th>Post Score F</th>\n",
       "      <th>Post Score F Error</th>\n",
       "      <th>Gain F</th>\n",
       "      <th>Norm Gain</th>\n",
       "      <th>Norm Gain Error</th>\n",
       "      <th>...</th>\n",
       "      <th>Post Score M</th>\n",
       "      <th>Post Score M Error</th>\n",
       "      <th>Gain M</th>\n",
       "      <th>Norm gain M</th>\n",
       "      <th>Norm gain error</th>\n",
       "      <th>Gain M Error</th>\n",
       "      <th>Gain M error sqrt</th>\n",
       "      <th>Num M</th>\n",
       "      <th>Avg M Grade</th>\n",
       "      <th>Avg M grade error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018 111</td>\n",
       "      <td>77.843750</td>\n",
       "      <td>1.318512</td>\n",
       "      <td>11.976744</td>\n",
       "      <td>0.811387</td>\n",
       "      <td>12.813953</td>\n",
       "      <td>0.974910</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.046452</td>\n",
       "      <td>0.038899</td>\n",
       "      <td>...</td>\n",
       "      <td>17.242105</td>\n",
       "      <td>0.687387</td>\n",
       "      <td>-0.126316</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>0.034499</td>\n",
       "      <td>0.966722</td>\n",
       "      <td>0.317903</td>\n",
       "      <td>95</td>\n",
       "      <td>75.407080</td>\n",
       "      <td>1.793091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018 112</td>\n",
       "      <td>73.650000</td>\n",
       "      <td>0.719146</td>\n",
       "      <td>9.790419</td>\n",
       "      <td>0.365908</td>\n",
       "      <td>14.107784</td>\n",
       "      <td>0.438484</td>\n",
       "      <td>4.317365</td>\n",
       "      <td>0.213630</td>\n",
       "      <td>0.016885</td>\n",
       "      <td>...</td>\n",
       "      <td>18.701149</td>\n",
       "      <td>0.658081</td>\n",
       "      <td>4.241379</td>\n",
       "      <td>0.272929</td>\n",
       "      <td>0.033626</td>\n",
       "      <td>0.874193</td>\n",
       "      <td>0.467313</td>\n",
       "      <td>87</td>\n",
       "      <td>73.434343</td>\n",
       "      <td>1.545714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018 112 001</td>\n",
       "      <td>74.471503</td>\n",
       "      <td>0.867428</td>\n",
       "      <td>9.990196</td>\n",
       "      <td>0.475061</td>\n",
       "      <td>13.852941</td>\n",
       "      <td>0.561047</td>\n",
       "      <td>3.862745</td>\n",
       "      <td>0.193043</td>\n",
       "      <td>0.020416</td>\n",
       "      <td>...</td>\n",
       "      <td>19.615385</td>\n",
       "      <td>0.820254</td>\n",
       "      <td>4.057692</td>\n",
       "      <td>0.280959</td>\n",
       "      <td>0.038941</td>\n",
       "      <td>1.096947</td>\n",
       "      <td>0.514066</td>\n",
       "      <td>52</td>\n",
       "      <td>76.089286</td>\n",
       "      <td>1.761654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018 112 002</td>\n",
       "      <td>72.401575</td>\n",
       "      <td>1.239442</td>\n",
       "      <td>9.476923</td>\n",
       "      <td>0.575170</td>\n",
       "      <td>14.507692</td>\n",
       "      <td>0.705447</td>\n",
       "      <td>5.030769</td>\n",
       "      <td>0.245127</td>\n",
       "      <td>0.029213</td>\n",
       "      <td>...</td>\n",
       "      <td>17.342857</td>\n",
       "      <td>1.064273</td>\n",
       "      <td>4.514286</td>\n",
       "      <td>0.262895</td>\n",
       "      <td>0.060863</td>\n",
       "      <td>1.378971</td>\n",
       "      <td>0.883434</td>\n",
       "      <td>35</td>\n",
       "      <td>69.976744</td>\n",
       "      <td>2.653168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           YEAR  Avg Grade  Avg Grade Error  Pre Score F  Pre Score F Error  \\\n",
       "1      2018 111  77.843750         1.318512    11.976744           0.811387   \n",
       "4      2018 112  73.650000         0.719146     9.790419           0.365908   \n",
       "5  2018 112 001  74.471503         0.867428     9.990196           0.475061   \n",
       "6  2018 112 002  72.401575         1.239442     9.476923           0.575170   \n",
       "\n",
       "   Post Score F  Post Score F Error    Gain F  Norm Gain  Norm Gain Error  \\\n",
       "1     12.813953            0.974910  0.837209   0.046452         0.038899   \n",
       "4     14.107784            0.438484  4.317365   0.213630         0.016885   \n",
       "5     13.852941            0.561047  3.862745   0.193043         0.020416   \n",
       "6     14.507692            0.705447  5.030769   0.245127         0.029213   \n",
       "\n",
       "   ...  Post Score M  Post Score M Error    Gain M  Norm gain M  \\\n",
       "1  ...     17.242105            0.687387 -0.126316    -0.010000   \n",
       "4  ...     18.701149            0.658081  4.241379     0.272929   \n",
       "5  ...     19.615385            0.820254  4.057692     0.280959   \n",
       "6  ...     17.342857            1.064273  4.514286     0.262895   \n",
       "\n",
       "   Norm gain error  Gain M Error  Gain M error sqrt  Num M  Avg M Grade  \\\n",
       "1         0.034499      0.966722           0.317903     95    75.407080   \n",
       "4         0.033626      0.874193           0.467313     87    73.434343   \n",
       "5         0.038941      1.096947           0.514066     52    76.089286   \n",
       "6         0.060863      1.378971           0.883434     35    69.976744   \n",
       "\n",
       "   Avg M grade error  \n",
       "1           1.793091  \n",
       "4           1.545714  \n",
       "5           1.761654  \n",
       "6           2.653168  \n",
       "\n",
       "[4 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2018\n",
    "\n",
    "df7 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "df7.loc[1] = by_gender_by_year(df18_111, \"2018 111\")\n",
    "df7.loc[4] = by_gender_by_year(df18_112, \"2018 112\")\n",
    "df7.loc[5] = by_gender_by_year(df18_112_001, \"2018 112 001\")\n",
    "df7.loc[6] = by_gender_by_year(df18_112_002, \"2018 112 002\")\n",
    "\n",
    "df7.to_excel(\"2018_by_lecture_section.xlsx\")\n",
    "\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>Avg Grade</th>\n",
       "      <th>Avg Grade Error</th>\n",
       "      <th>Pre Score F</th>\n",
       "      <th>Pre Score F Error</th>\n",
       "      <th>Post Score F</th>\n",
       "      <th>Post Score F Error</th>\n",
       "      <th>Gain F</th>\n",
       "      <th>Norm Gain</th>\n",
       "      <th>Norm Gain Error</th>\n",
       "      <th>...</th>\n",
       "      <th>Post Score M</th>\n",
       "      <th>Post Score M Error</th>\n",
       "      <th>Gain M</th>\n",
       "      <th>Norm gain M</th>\n",
       "      <th>Norm gain error</th>\n",
       "      <th>Gain M Error</th>\n",
       "      <th>Gain M error sqrt</th>\n",
       "      <th>Num M</th>\n",
       "      <th>Avg M Grade</th>\n",
       "      <th>Avg M grade error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016 111</td>\n",
       "      <td>73.690909</td>\n",
       "      <td>0.852871</td>\n",
       "      <td>12.659091</td>\n",
       "      <td>0.553295</td>\n",
       "      <td>15.079545</td>\n",
       "      <td>0.598941</td>\n",
       "      <td>2.420455</td>\n",
       "      <td>0.139581</td>\n",
       "      <td>0.030271</td>\n",
       "      <td>...</td>\n",
       "      <td>19.353982</td>\n",
       "      <td>0.657655</td>\n",
       "      <td>0.929204</td>\n",
       "      <td>0.080275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.850069</td>\n",
       "      <td>0.366009</td>\n",
       "      <td>113</td>\n",
       "      <td>74.929688</td>\n",
       "      <td>1.314253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016 112</td>\n",
       "      <td>67.096220</td>\n",
       "      <td>0.980007</td>\n",
       "      <td>8.380368</td>\n",
       "      <td>0.337758</td>\n",
       "      <td>13.141104</td>\n",
       "      <td>0.423311</td>\n",
       "      <td>4.760736</td>\n",
       "      <td>0.220204</td>\n",
       "      <td>0.026061</td>\n",
       "      <td>...</td>\n",
       "      <td>17.592593</td>\n",
       "      <td>0.761897</td>\n",
       "      <td>3.876543</td>\n",
       "      <td>0.238059</td>\n",
       "      <td>0.043003</td>\n",
       "      <td>0.983351</td>\n",
       "      <td>0.548112</td>\n",
       "      <td>81</td>\n",
       "      <td>65.086957</td>\n",
       "      <td>1.938844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2016 112 001</td>\n",
       "      <td>67.069620</td>\n",
       "      <td>1.369968</td>\n",
       "      <td>8.010870</td>\n",
       "      <td>0.418885</td>\n",
       "      <td>13.108696</td>\n",
       "      <td>0.561220</td>\n",
       "      <td>5.097826</td>\n",
       "      <td>0.231834</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>...</td>\n",
       "      <td>17.390244</td>\n",
       "      <td>1.148635</td>\n",
       "      <td>3.560976</td>\n",
       "      <td>0.220211</td>\n",
       "      <td>0.056140</td>\n",
       "      <td>1.462866</td>\n",
       "      <td>0.763535</td>\n",
       "      <td>41</td>\n",
       "      <td>64.425532</td>\n",
       "      <td>2.904229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2016 112 002</td>\n",
       "      <td>68.805825</td>\n",
       "      <td>1.520909</td>\n",
       "      <td>8.786885</td>\n",
       "      <td>0.602869</td>\n",
       "      <td>13.049180</td>\n",
       "      <td>0.705725</td>\n",
       "      <td>4.262295</td>\n",
       "      <td>0.200927</td>\n",
       "      <td>0.060435</td>\n",
       "      <td>...</td>\n",
       "      <td>18.111111</td>\n",
       "      <td>1.299061</td>\n",
       "      <td>4.185185</td>\n",
       "      <td>0.260369</td>\n",
       "      <td>0.092880</td>\n",
       "      <td>1.698214</td>\n",
       "      <td>1.075547</td>\n",
       "      <td>27</td>\n",
       "      <td>70.607143</td>\n",
       "      <td>2.884615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2016 112 003</td>\n",
       "      <td>61.366667</td>\n",
       "      <td>3.199311</td>\n",
       "      <td>9.300000</td>\n",
       "      <td>1.422439</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1.712698</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>0.227053</td>\n",
       "      <td>0.061755</td>\n",
       "      <td>...</td>\n",
       "      <td>17.153846</td>\n",
       "      <td>1.604665</td>\n",
       "      <td>4.230769</td>\n",
       "      <td>0.247748</td>\n",
       "      <td>0.068595</td>\n",
       "      <td>2.134298</td>\n",
       "      <td>1.044852</td>\n",
       "      <td>13</td>\n",
       "      <td>57.823529</td>\n",
       "      <td>4.361627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           YEAR  Avg Grade  Avg Grade Error  Pre Score F  Pre Score F Error  \\\n",
       "1      2016 111  73.690909         0.852871    12.659091           0.553295   \n",
       "4      2016 112  67.096220         0.980007     8.380368           0.337758   \n",
       "5  2016 112 001  67.069620         1.369968     8.010870           0.418885   \n",
       "6  2016 112 002  68.805825         1.520909     8.786885           0.602869   \n",
       "7  2016 112 003  61.366667         3.199311     9.300000           1.422439   \n",
       "\n",
       "   Post Score F  Post Score F Error    Gain F  Norm Gain  Norm Gain Error  \\\n",
       "1     15.079545            0.598941  2.420455   0.139581         0.030271   \n",
       "4     13.141104            0.423311  4.760736   0.220204         0.026061   \n",
       "5     13.108696            0.561220  5.097826   0.231834         0.021861   \n",
       "6     13.049180            0.705725  4.262295   0.200927         0.060435   \n",
       "7     14.000000            1.712698  4.700000   0.227053         0.061755   \n",
       "\n",
       "   ...  Post Score M  Post Score M Error    Gain M  Norm gain M  \\\n",
       "1  ...     19.353982            0.657655  0.929204     0.080275   \n",
       "4  ...     17.592593            0.761897  3.876543     0.238059   \n",
       "5  ...     17.390244            1.148635  3.560976     0.220211   \n",
       "6  ...     18.111111            1.299061  4.185185     0.260369   \n",
       "7  ...     17.153846            1.604665  4.230769     0.247748   \n",
       "\n",
       "   Norm gain error  Gain M Error  Gain M error sqrt  Num M  Avg M Grade  \\\n",
       "1              NaN      0.850069           0.366009    113    74.929688   \n",
       "4         0.043003      0.983351           0.548112     81    65.086957   \n",
       "5         0.056140      1.462866           0.763535     41    64.425532   \n",
       "6         0.092880      1.698214           1.075547     27    70.607143   \n",
       "7         0.068595      2.134298           1.044852     13    57.823529   \n",
       "\n",
       "   Avg M grade error  \n",
       "1           1.314253  \n",
       "4           1.938844  \n",
       "5           2.904229  \n",
       "6           2.884615  \n",
       "7           4.361627  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2016\n",
    "\n",
    "df8 = pd.DataFrame(columns=column_names)\n",
    "\n",
    "df8.loc[1] = by_gender_by_year(df16_111, \"2016 111\")\n",
    "df8.loc[4] = by_gender_by_year(df16_112, \"2016 112\")\n",
    "df8.loc[5] = by_gender_by_year(df16_112_001, \"2016 112 001\")\n",
    "df8.loc[6] = by_gender_by_year(df16_112_002, \"2016 112 002\")\n",
    "df8.loc[7] = by_gender_by_year(df16_112_003, \"2016 112 003\")\n",
    "\n",
    "df8.to_excel(\"2016_by_lecture_section.xlsx\")\n",
    "\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
